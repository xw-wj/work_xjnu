import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# åŠ è½½æ¨¡å‹
model_path = "./outputs/bert_imdb_model"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path)
model.eval()

# æµ‹è¯•æ ·ä¾‹
test_reviews = [
    "This movie is absolutely amazing! I loved every minute of it.",
    "Terrible film. Complete waste of time and money.",
    "It was okay, nothing special but entertaining enough."
]

print("="*60)
print("IMDBæƒ…æ„Ÿåˆ†ç±»é¢„æµ‹")
print("="*60)

for review in test_reviews:
    # ç¼–ç 
    inputs = tokenizer(review, return_tensors="pt", truncation=True, max_length=512)
    
    # é¢„æµ‹
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.softmax(outputs.logits, dim=1)
        pred = torch.argmax(probs, dim=1).item()
    
    sentiment = "æ­£é¢ ğŸ˜Š" if pred == 1 else "è´Ÿé¢ ğŸ˜”"
    confidence = probs[0][pred].item()
    
    print(f"\nè¯„è®º: {review}")
    print(f"æƒ…æ„Ÿ: {sentiment}")
    print(f"ç½®ä¿¡åº¦: {confidence:.2%}")